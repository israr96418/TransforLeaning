{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **Transfer learning**\n",
        "\n",
        "- when we are using pretrained model we must watch to domain and task of our own problem and pretrained model<br>\n",
        "Full documentation link is here: https://www.learndatasci.com/tutorials/hands-on-transfer-learning-keras/\n",
        "\n",
        "- github repo link: https://github.com/gabrielcassimiro17/object-detection/blob/main/transfer_learning.ipynb\n",
        "\n",
        "- **Example :**VGG16 train on imagenet dataset contain 14million hight resolution images and 1000 class/label\n",
        "Our goal is classification(flower) but pretained model VGG16 cannot contain flower images\n",
        "- The VGG16 network was not trained to classify different kinds of flowers."
      ],
      "metadata": {
        "id": "pGgwyxD62-bb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Install required libraries**"
      ],
      "metadata": {
        "id": "AR1RHBrZ6Gf2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow_datasets tensorflow keras"
      ],
      "metadata": {
        "id": "BKOFt7m_6OeO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Load dataset from Tensorflow**\n"
      ],
      "metadata": {
        "id": "HyELBn-R5o2q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "## Loading images and labels\n",
        "(train_ds, train_labels), (test_ds, test_labels) = tfds.load(\n",
        "    \"tf_flowers\",\n",
        "    split=[\"train[:70%]\", \"train[:30%]\"], ## Train test split\n",
        "    batch_size=-1,\n",
        "    as_supervised=True,  # Include labels\n",
        ")\n",
        "\n",
        "## Resizing images\n",
        "train_ds = tf.image.resize(train_ds, (150, 150))\n",
        "test_ds = tf.image.resize(test_ds, (150, 150))\n",
        "\n",
        "## Transforming labels to correct format\n",
        "train_labels = to_categorical(train_labels, num_classes=5)\n",
        "test_labels = to_categorical(test_labels, num_classes=5)"
      ],
      "metadata": {
        "id": "988LWTmy3BFX"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GZYMiUVO6-Yy",
        "outputId": "a3eb091f-1e86-4bbe-bdff-ce4bd80f9763"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 1., 0., 0.],\n",
              "       [0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 1., 0.],\n",
              "       ...,\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   We use Include_top=False to remove the classification layer that was trained on the ImageNet dataset and set the model as not trainable\n",
        "2.   Also, we used the preprocess_input function from VGG16 to normalize the input data.\n",
        "\n"
      ],
      "metadata": {
        "id": "mxB5M-WR-0dC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
        "\n",
        "##load VGG16 model\n",
        "\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=train_ds[0].shape)\n",
        "base_model.trainable = False   # not trainable weights\n",
        "\n",
        "# preprocess the input\n",
        "train_ds = preprocess_input(train_ds)\n",
        "test_ds = preprocess_input(test_ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8lx0_E1T7GQL",
        "outputId": "09dd3391-05a2-4ead-fe73-afb5ab1cf351"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**check model summary**\n"
      ],
      "metadata": {
        "id": "456JLkyJ_FlP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D57ndCWO_IcJ",
        "outputId": "7e98885c-1f50-4451-ddda-34ba670d4c3d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 150, 150, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 150, 150, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 150, 150, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 75, 75, 64)        0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 75, 75, 128)       73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 75, 75, 128)       147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 37, 37, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 37, 37, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 37, 37, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 37, 37, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 18, 18, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 18, 18, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 18, 18, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 18, 18, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 9, 9, 512)         0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 9, 9, 512)         2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 9, 9, 512)         2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 9, 9, 512)         2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 4, 4, 512)         0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14714688 (56.13 MB)\n",
            "Trainable params: 0 (0.00 Byte)\n",
            "Non-trainable params: 14714688 (56.13 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**Two main points:**\n",
        "- the model has over 14 Million trained parameters\n",
        "- and ends with a maxpooling layer that belongs to the Feature Learning part of the network."
      ],
      "metadata": {
        "id": "cG72H3y6CLLt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we add the last layers for our specific problem.<br>\n",
        "\"cutt-off\" --> the fullyconnect layers which are called top model"
      ],
      "metadata": {
        "id": "J4ZmP_Q2CdI1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers, models\n",
        "\n",
        "flatten_layers = layers.Flatten()\n",
        "dense_layer1 = layers.Dense(50, activation = 'relu')\n",
        "dense_layer2 = layers.Dense(20, activation = 'relu')\n",
        "prediction_layers = layers.Dense(5, activation='softmax')\n",
        "\n",
        "\n",
        "model = models.Sequential([\n",
        "    base_model,\n",
        "    flatten_layers,\n",
        "    dense_layer1,\n",
        "    dense_layer2,\n",
        "    prediction_layers\n",
        "])"
      ],
      "metadata": {
        "id": "MscU0PFz_KrY"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "yvXgtFJDFMeQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Add compile and fit the model**"
      ],
      "metadata": {
        "id": "CT8eITn-FM9A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss = 'categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "\n",
        "# add EarlyStopping layers--> this layers monitor val_accuracy  if it maximum then stop our model training\n",
        "# and store weights\n",
        "\n",
        "early_stopping = EarlyStopping(monitor = 'val_accuracy', mode =\"max\", patience=5, restore_best_weights=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "fvRyRx38FKSb"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Strat model training by using callbacks for monitoring**"
      ],
      "metadata": {
        "id": "wfoNIjN9IvF6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_ds, train_labels, epochs=10, validation_split=0.2,  callbacks=[early_stopping], batch_size=32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-tvFMYQaIMhk",
        "outputId": "deb8ddd8-4cdc-42cd-b863-3a31a23cd673"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "65/65 [==============================] - 18s 127ms/step - loss: 2.1347 - accuracy: 0.5197 - val_loss: 1.0951 - val_accuracy: 0.5992\n",
            "Epoch 2/10\n",
            "65/65 [==============================] - 6s 87ms/step - loss: 0.6983 - accuracy: 0.7411 - val_loss: 1.0174 - val_accuracy: 0.6323\n",
            "Epoch 3/10\n",
            "65/65 [==============================] - 6s 88ms/step - loss: 0.4311 - accuracy: 0.8380 - val_loss: 0.9681 - val_accuracy: 0.6576\n",
            "Epoch 4/10\n",
            "65/65 [==============================] - 5s 83ms/step - loss: 0.2996 - accuracy: 0.8891 - val_loss: 1.0389 - val_accuracy: 0.6907\n",
            "Epoch 5/10\n",
            "65/65 [==============================] - 6s 88ms/step - loss: 0.2190 - accuracy: 0.9299 - val_loss: 1.0165 - val_accuracy: 0.6965\n",
            "Epoch 6/10\n",
            "65/65 [==============================] - 6s 87ms/step - loss: 0.1647 - accuracy: 0.9426 - val_loss: 1.0601 - val_accuracy: 0.6907\n",
            "Epoch 7/10\n",
            "65/65 [==============================] - 6s 87ms/step - loss: 0.1273 - accuracy: 0.9572 - val_loss: 1.1492 - val_accuracy: 0.6965\n",
            "Epoch 8/10\n",
            "65/65 [==============================] - 6s 89ms/step - loss: 0.0873 - accuracy: 0.9723 - val_loss: 1.1820 - val_accuracy: 0.7043\n",
            "Epoch 9/10\n",
            "65/65 [==============================] - 6s 88ms/step - loss: 0.0826 - accuracy: 0.9810 - val_loss: 1.2242 - val_accuracy: 0.7160\n",
            "Epoch 10/10\n",
            "65/65 [==============================] - 6s 90ms/step - loss: 0.0513 - accuracy: 0.9873 - val_loss: 1.2704 - val_accuracy: 0.7179\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x79673a97d060>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Evaluating this model on test data**"
      ],
      "metadata": {
        "id": "3fYsQtZ8Jd9r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(test_ds, test_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qinPgt0kI5Ar",
        "outputId": "ef1d2ade-02bd-4257-9a42-b9759b36deb9"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "35/35 [==============================] - 3s 95ms/step - loss: 0.0541 - accuracy: 0.9855\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.054106153547763824, 0.9854677319526672]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "mW3Ia6v_KQsH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Train the CNN model from scratch on the same dataset and compare it with pre-train model**"
      ],
      "metadata": {
        "id": "KNrvxVN_KQ8a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import Sequential , layers\n",
        "from tensorflow.keras.callbacks import EarlyStopping  # for monitoring\n",
        "from tensorflow.keras.layers.experimental.preprocessing import Rescaling"
      ],
      "metadata": {
        "id": "9EwF4aC1Jy9c"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "own_model = Sequential()\n",
        "\n",
        "own_model.add(Rescaling(1./255, input_shape=(150,150,3)))\n",
        "\n",
        "own_model.add(layers.Conv2D(16, kernel_size=10, activation='relu'))\n",
        "own_model.add(layers.MaxPooling2D(3))\n",
        "\n",
        "\n",
        "own_model.add(layers.Conv2D(32, kernel_size=8, activation=\"relu\"))\n",
        "own_model.add(layers.MaxPooling2D(2))\n",
        "\n",
        "own_model.add(layers.Conv2D(32, kernel_size=6, activation=\"relu\"))\n",
        "own_model.add(layers.MaxPooling2D(2))\n",
        "\n",
        "own_model.add(layers.Flatten())\n",
        "own_model.add(layers.Dense(50, activation='relu'))\n",
        "own_model.add(layers.Dense(20, activation='relu'))\n",
        "own_model.add(layers.Dense(5, activation = 'softmax'))\n"
      ],
      "metadata": {
        "id": "II4I5M4eK7Vf"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "own_model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy'],\n",
        ")\n",
        "\n",
        "\n",
        "es = EarlyStopping(monitor='val_accuracy', mode='max', patience=5,  restore_best_weights=True)\n",
        "\n",
        "own_model.fit(train_ds, train_labels, epochs=50, validation_split=0.2, batch_size=32, callbacks=[es])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zx4kUiXpMUvm",
        "outputId": "a00c1f28-4f9c-4633-fe08-85dcf64eabcb"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "65/65 [==============================] - 6s 30ms/step - loss: 1.5768 - accuracy: 0.2545 - val_loss: 1.4958 - val_accuracy: 0.3444\n",
            "Epoch 2/50\n",
            "65/65 [==============================] - 2s 25ms/step - loss: 1.3540 - accuracy: 0.3981 - val_loss: 1.2658 - val_accuracy: 0.4864\n",
            "Epoch 3/50\n",
            "65/65 [==============================] - 1s 21ms/step - loss: 1.2428 - accuracy: 0.4545 - val_loss: 1.2525 - val_accuracy: 0.4981\n",
            "Epoch 4/50\n",
            "65/65 [==============================] - 1s 23ms/step - loss: 1.1755 - accuracy: 0.5007 - val_loss: 1.1797 - val_accuracy: 0.4942\n",
            "Epoch 5/50\n",
            "65/65 [==============================] - 1s 23ms/step - loss: 1.1346 - accuracy: 0.5139 - val_loss: 1.1302 - val_accuracy: 0.5195\n",
            "Epoch 6/50\n",
            "65/65 [==============================] - 1s 23ms/step - loss: 1.0356 - accuracy: 0.5586 - val_loss: 1.1010 - val_accuracy: 0.5331\n",
            "Epoch 7/50\n",
            "65/65 [==============================] - 1s 20ms/step - loss: 0.9630 - accuracy: 0.6078 - val_loss: 1.1968 - val_accuracy: 0.5311\n",
            "Epoch 8/50\n",
            "65/65 [==============================] - 1s 20ms/step - loss: 0.8854 - accuracy: 0.6462 - val_loss: 1.1363 - val_accuracy: 0.5525\n",
            "Epoch 9/50\n",
            "65/65 [==============================] - 1s 20ms/step - loss: 0.8182 - accuracy: 0.6735 - val_loss: 1.2850 - val_accuracy: 0.5447\n",
            "Epoch 10/50\n",
            "65/65 [==============================] - 2s 24ms/step - loss: 0.7582 - accuracy: 0.7056 - val_loss: 1.1940 - val_accuracy: 0.5370\n",
            "Epoch 11/50\n",
            "65/65 [==============================] - 2s 26ms/step - loss: 0.6797 - accuracy: 0.7372 - val_loss: 1.2032 - val_accuracy: 0.5370\n",
            "Epoch 12/50\n",
            "65/65 [==============================] - 1s 23ms/step - loss: 0.5692 - accuracy: 0.7786 - val_loss: 1.2953 - val_accuracy: 0.5661\n",
            "Epoch 13/50\n",
            "65/65 [==============================] - 1s 20ms/step - loss: 0.4867 - accuracy: 0.8063 - val_loss: 1.5567 - val_accuracy: 0.5331\n",
            "Epoch 14/50\n",
            "65/65 [==============================] - 1s 20ms/step - loss: 0.4580 - accuracy: 0.8146 - val_loss: 1.8115 - val_accuracy: 0.5623\n",
            "Epoch 15/50\n",
            "65/65 [==============================] - 1s 20ms/step - loss: 0.3994 - accuracy: 0.8579 - val_loss: 1.5678 - val_accuracy: 0.5486\n",
            "Epoch 16/50\n",
            "65/65 [==============================] - 1s 21ms/step - loss: 0.3464 - accuracy: 0.8808 - val_loss: 1.6870 - val_accuracy: 0.5331\n",
            "Epoch 17/50\n",
            "65/65 [==============================] - 1s 20ms/step - loss: 0.2681 - accuracy: 0.8998 - val_loss: 1.8534 - val_accuracy: 0.5195\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x796702ecd600>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Again evaluate our own train model that we are train from scratch**"
      ],
      "metadata": {
        "id": "_G73LyJJMs3j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "own_model.evaluate(test_ds, test_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-uz7m9EoMoUZ",
        "outputId": "be8c7667-be71-44bb-8f28-1219f0404bc6"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "35/35 [==============================] - 1s 15ms/step - loss: 0.4236 - accuracy: 0.8520\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.42360004782676697, 0.8519527912139893]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Compare the result of own train model that we made it from scrach and result of using pre-traine model<br>\n",
        "-The result of pre-trian model is better the model which are made from scratch"
      ],
      "metadata": {
        "id": "0sU-oDOCM9T-"
      }
    }
  ]
}